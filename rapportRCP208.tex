
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Wenneker Assignment
% LaTeX Template

% Version 2.0 (12/1/2019)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@LaTeXTemplates.com)
% Frits Wenneker
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt]{scrartcl} % Font size

\input{structure.tex} % Include the file specifying the document structure and custom commands
\usepackage{hyperref}
 
\urlstyle{same}
%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{	
	\normalfont\normalsize
	\textsc{CNAM}\\ % Your university, school and/or department name(s)
	\vspace{25pt} % Whitespace
	\rule{\linewidth}{0.5pt}\\ % Thin top horizontal rule
	\vspace{20pt} % Whitespace
	{\huge Projet RCP208 : Compte Rendu TD}\\ % The assignment title
	\vspace{12pt} % Whitespace
	\rule{\linewidth}{2pt}\\ % Thick bottom horizontal rule
	\vspace{12pt} % Whitespace
}

\author{\LARGE Jérôme Petit} % Your name

\date{\normalsize\today} % Today's date (\today) or a custom date

\begin{document}

\maketitle % Print the title


\section{TD K-means}
\subsection{CR : variable uniforme}
Je génère 500 variables uniformes auquel j'associe 5 étiquettes (1,2,3,4,5), ci dessous un exemple de données générées~:
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{uniform.png}
\end{figure}
\newline
En appliquant une classification par K-means avec les paramètres : n\_init=1, nb\_clusters =5 et une initialisation : k-means++, on obtient la classification suivante~: 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{uniformKmeans.png}
\end{figure}
\newline
Afin de déterminer la qualité de la classification j'ai utilisé la métrique de Rand ajusté et de Jacquard. Pour l'échantillon précédent je trouve une valeur de 0.0059947710270688665 pour Rand ajusté et 0.176 pour Jacquard. Les valeurs obtenues sont très faibles par rapport à des données suivant une normale et séparées. Cette valeur faible provient du faite qu'il n'y a pas de cluster apparent, il est donc impossible d'avoir une séparation efficace par cluster des données. Malgré cela, Les résultats obtenues sont stables, en effet en faisant 10 classifications, on obtient les résultats suivant~: indice de Rand ajusté : moyenne 0.0048179719511162265 et écart type :0.0025297897570419775
\newline
Si l'on utilise la même approche pour la génération de variables normales (on génère les variables puis on les sépare afin d'avoir des clusters) alors on a les données suivantes :
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{unifor_lag.png}
\end{figure}
\newline
En appliquant une classification par K-means avec les paramètres : n\_init=1, nb\_clusters =5 et initialisation : k-means++, on obtient la classification suivante~:
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{uniform_lagKmeans.png}
\end{figure}
\newline
Dans ce cas, on obtient des résultats légèrement meilleur à ceux obtenues par variables normales. Ce résultat est cohérent avec la méthode K-means. Cette méthode détecte les clusters et n'est pas sensible à la distribution des variables. Les résultats sont donc légèrement meilleur car on a  dans le cas uniforme les clusters sont plus disjoint que dans le cas normale (variance plus faible). Pour les variables uniformes après avoir fait 10 classification K-means (avec initialisation k-means++, nb\_cluster=5 et n\_init=1) j'obtiens un indice de rand ajusté en moyenne de 1.0 et d'écart type 0.0.
\subsection{CR : Texture}
En appliquant l'approche K-means avec 11 cluster, une initialisation K-means++ et n\_init=1, on obtient un score de Rand ajusté de 0.46479949030200746. La classification obtenue n'est pas de bonne qualité. Cela vient du fait que l'on utilise l'algorithme K-means sur des données ayant 40 variables. Afin de réduire ce nombre de variables et de faire apparaitre les axes contenant l'information nécessaire on utilise une approche discriminante. En utilisant 10 axes, on obtient les ratio de variances suivant : axe 1 : 45.86\%, axe 2 : 24.24\%, axe 3 : 9.65\% , axe 4 : 6.94\%, axe 5 :  5.54\% , axe 6 : 2.42\%, axe 7 :
 2.26\%, axe 8 : 1.56\% axe 9 : 0.84\% et l'axe 10: 0.68\%. Ce qui signifie que les 5 premiers axes représente 90\% de la variance. Grâce à l'analyse factoriel on s'est ramené à 10 variables. En appliquant alors le même algorithme K-means, on a cette fois ci un score de Rand ajusté de 0.9956363636363637. Afin de déterminé quel est la projection optimal j'ai réalisé la méthode classification pour des nombres de composants allant de 1 à 20. Le score de rand ajusté obtenu par le K-means est le suivant : 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{AFD_K_means.png}
\end{figure}
\newline 
Ainsi une AFD à 8 composants va donner un résultat similaire à une AFD à 20 composants. Ci dessous est le jeu de données initial projeté sur les 3 premiers axes~: 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{init.png}
\end{figure}
\newline 

On ne voit pas apparaitre clairement de cluster. A l'aide de l'AFD on va pouvoir réduire le nombre de variables à 8 tout en préservant la dispersion~:
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{AFD8.png}
\end{figure}
\newline 

Les clusters apparaissent plus clairement en utilisant une classification K-means avec 11 clusters et une initialisation K-means++, on obtient la classification suivante~:
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{kmeans_AFD8.png}
\end{figure}
\newline 
\section{Classification spectrale}
\subsection{Variable uniforme}
Comme pour le TD K-means j'ai généré des données suivant la loi uniform  [0,1]. Ci dessous se trouve les données générées : 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.5]{unifSpectrale.png}
\end{figure}
\newline 
En appliquant l'analyse spectrale sur les données en utilisant la méthodes de proches voisins pour la création de la matrice de similarité on remarque une instabilité des résultats. Ci dessous se trouve les valeurs de l'indice de Rand ajusté en fonction du nombre n\_neighbors choisi (entre 1 et 20) : 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{spectralUnifNN.png}
\end{figure}
\newline 
Par contre comme dans le cas normal on observe une très bonne classification par le noyau rbf pour des valeurs de $\gamma\leq 8$ (indice de rand ajusté vaut 1). La classification est moins stable pour des valeurs de $\gamma >8$. 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{spectralUnifRBF.png}
\end{figure}
\newline 
L'approche par K-means est beaucoup plus stable que l'analyse spectrale. En effet, on a un indice de rand ajusté de 1.0 avec une initialisation k-means++. L'approche k-means est de meilleur qualité avec une initialisation k-means++ car les cluster sont disjoints ce qui est un cas adapté pour cette méthode. De plus l'analyse spectrale donne de moins bon résultats pour gamma > 8 car il y a trop de composantes connexes. Pour des valeurs inférieur à 8 les résultats sont similaire à l'approche k-means.
\subsection{données : Texture}
Sans appliquer l'AFD afin de réduire la dimension, la classification spectrale avec la méthode des proches voisins et n\_neighbors=9$\approx$ log(5500)+1 donne un indice de Rand ajusté de 0.6007141289011186. Afin d'améliorer ce résultat, j'utilise une AFD qui va réduire la nombre de variables afin de les regrouper de la plus explicative à la moins explicative (ce critère est donné par la variance). Comme pour l'étude K-means, nous observons que 8 composantes donne un résultat similaire à 20 composantes. En appliquant une méthode spectrale après avoir appliqué une AFD à 8 composantes. Avec ses conditions on obtient un indice de Rand ajsuté de : 0.8146208480795527 et la classification suivante (projection sur les 3 premières composantes)
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.5]{spectraleAFD.png}
\end{figure}
\newline 
Contrairement à la méthode K-means la stabilité des résultats est moindre, cela vient du nombre de composantes connexes en jeu. Ci dessous la valeur de l'indice de Rand ajusté en fonction du nombre de composantes de l'AFD (la méthode spectrale utilisée est celle des proches voisins avec 9 voisins)
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{metricsAFDNN.png}
\end{figure}
\newline 
\section{TD : mélange de densité}
En utilisant 100 données et 2 composantes la densité obtenue est proche de la vraie densité, la valeur de la log vraisemblance est de -2.0139415707841097~:
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{densite100.png}
\end{figure}
\newline 
En augmentant le nombre d'échantillon : N=10000, on obtient une log vraisemblance de : -2.011940707075323. La densité obtenue correspond exactement à la vrai densité : 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{densite10000.png}
\end{figure}
\newline 
Étant donné que la qualité de l'estimation pour N=10000 est équivalente à celle pour N=100, j'ai étudié l'évolution de la log vraisemblance en fonction du nombre de composantes pour N=100. Ci dessous le graphe de la log vraisemblance en fonction du nombre de composantes utilisées dans l'estimation (entre 1 et 20) : 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{log100.png}
\end{figure}
\newline 
\newline
\newline
\newline 
\newline
\newline
\newline 
\newline
\newline
\newline 
\newline
\newline
On observe que plus le nombre de composantes  augmente plus la log vraisemblance augmente. Mais l'augmentation du nombre de composantes nécessite plus de données en effet pour N=100 et 8 composantes on a~:
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{densite8cpt.png}
\end{figure}
\newline 
En utilisant 10000 données et 8 composantes l'approximation est meilleure qualité mais l'approximation reste de moins bonne qualité que celle obtenue avec 2 composantes~:
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{densite8cpt10000.png}
\end{figure}
\newline  
\subsection{critere AIC}
En utilisant \textit{diag} au lieu de \textit{full} dans l'estimation, on obtient la même classification, en effet les minimum des critères AIC et BIC sont obtenues pour 3 composantes. Dans le cas \textit{diag} le minimum AIC est plus faible que dans le cas \textit{full}~:
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.3]{barAIC.png}
\end{figure}
\newline 
\subsection{Textures}
La nombre de composantes est de 8 alors que le nombre de classes est de 11. Cette différence vient du fait que l'algorithme EM n'arrive pas à séparer certaine classes entre elles. En utilisant 8 composantes on a la solution optimale selon les critères AIC et BIC, cela signifie optimal au sens de la log vraisemblance et de la complexité des modèles. Ainsi si l'on augmente le nombre de composant  l'opposée de la log-vraisemblance diminue moins que la complexité ainsi la valeur d'AIC et BIC augmente. Ainsi si l'on augmente le nombre de composantes à 11 on aura un modèle qui aura une meilleur log-vraisemblance que 8 mais cet écart dans la log-vraisemblance est moindre que l'augmentation de la complexité.

En utilisant une AFD sur les 2 premiers paramètre, le profil des critères AIC est le suivant : 
\newline
\begin{figure}[!h]
 \centering 
\includegraphics[scale=.4]{AICAFD.png}
\end{figure}
\newline 
La valeur du critère est minimum pour 12 composantes et se stabilise à partir de 10. L'utilisation de l'AFD permet de réduire la dimension et de pouvoir utiliser des modèles plus complexes avec une meilleur précision. Cela est du au fait que les données projetées obtenues par l'AFD sont bien séparées il est donc plus facile pour le modèles de mélange de déterminer la distribution sur chacun des cluster. Si les données sont mélangées et donc ayant une région d'intersection plus grande, l'approche par mélange gaussien donnera de moins bon résultat et ne permettra pas de bien déterminer les distributions sur les zones d'intersection. C'est pourquoi on a 8 composants dans le premier et 11 avec l'AFD.
\end{document}